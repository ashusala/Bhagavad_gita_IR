{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training our model\n",
    "model = fasttext.train_unsupervised('data_preprocessed.txt', \"cbow\", minn = 2, maxn = 13, epoch = 1, dim = 50, thread = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ashu': 1,\n",
       " 'is': 1,\n",
       " 'a': 1,\n",
       " 'bitchs': 1,\n",
       " 'buoy': 1,\n",
       " 'he': 1,\n",
       " 'doesnt': 1,\n",
       " 'like': 1,\n",
       " 'himself': 1,\n",
       " 'much': 1,\n",
       " 'either': 1}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string_ = \"Ashu is a bitch's buoy! He doesn't like himself much either.\"\n",
    "# this pre_processing will make verse suitable for setnece embeddings.\n",
    "string_ = string_.lower().translate(str.maketrans('','',string.punctuation)).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to get the word frequency of each word in a verse/sentence\n",
    "# list_of_words: a pre-processed list of words in a verse/sentence.\n",
    "def word_count(list_of_words):\n",
    "    # a dictionary keeping frequency for all the unique words\n",
    "    counts = dict()\n",
    "    \n",
    "    for word in list_of_words:\n",
    "        # if the word is already listed, increasing its count\n",
    "        if word in counts:\n",
    "            counts[word] += 1\n",
    "        # else putting the new word in our dictionary\n",
    "        else:\n",
    "            counts[word] = 1\n",
    "\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to calculate composite sentence/verse embeddings\n",
    "# verse has to be given in a tokenzied format to this.\n",
    "def senemb(alpha, verse_tok, model, dim):\n",
    "    # creating an empty vector\n",
    "    sentEmb = np.zeros(dim)\n",
    "    v_count = word_count(verse_tok)\n",
    "    \n",
    "    for word in verse_tok:\n",
    "        prob = alpha / (alpha + v_count[word]/len(verse))\n",
    "        sentEmb = sentEmb +  model.get_word_vector(word) * prob\n",
    "        \n",
    "    return sentEmb/len(verse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we calculate the sentence embedding vectors for verses\n",
    "\n",
    "# let's get all the verses and get their vectors\n",
    "verses = pd.read_csv('verses.csv', usecols=['#verse', 'Translation'])\n",
    "data = verses['Translation'].to_list()\n",
    "\n",
    "# a list to store all the vectors\n",
    "verse_vectors = []\n",
    "\n",
    "# looping over all the verses\n",
    "for verse in data:\n",
    "    # tokenizing and preprocessing the verse\n",
    "    verse_tok = verse.lower().translate(str.maketrans('','',string.punctuation)).split() \n",
    "    verse_vectors.append(senemb(1, verse_tok, model, 50))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we calculate the sentence embedding vectors for queries\n",
    "\n",
    "# getting the queries\n",
    "df = pd.read_csv('queries_syn.csv')\n",
    "queries = df['Verse'].to_list()\n",
    "\n",
    "# pre-processing the queries\n",
    "queries = [query.lower().translate(str.maketrans('','',string.punctuation)).split() for query in queries]\n",
    "\n",
    "# a list to store all the vectors\n",
    "query_vectors = []\n",
    "\n",
    "for query in queries:\n",
    "    query_vectors.append(senemb(1, query, model, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's find the best matching queries for all our queries\n",
    "for i, query in enumerate(queries):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
